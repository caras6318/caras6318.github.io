---
title: CS Memory
date: 2024-04-22 04:04 +0900
categories: CS
tags:
  - CS
  - RAM
---
## Intro
---
이번 포스팅부터는 RAM 즉, 메모리에 대해서 공부한 내용들을 정리해보았다.
>아래 내용은 공부한 내용을 정리한 것으로 틀린 내용이 포함되어 있을 수 있습니다.  

## RAM
---
RAM (Random Access Memory) 에는 실행할 프로그램의 명령어와 데이터가 저장된다.
하지만 HDD 나 SSD 같은 보조기억장치들과는 다른 특징이 있는데 바로 전원이 꺼지면 저장된 명령어와 데이터가 모두 날아가는 *휘발성 저장 장치* 라는 점이다.

보조기억장치는 전원을 꺼도 내용이 저장되는 *비휘발성 저장 장치* 이지만 CPU 는 직접 접근을 하지 못하기 때문에 일반적으로 SSD나 HDD에는 *보관할 대상*을 저장하고 RAM같은 주 기억 장치에는 *실행할 대상* 을 저장하게된다.

RAM 용량이 크면 어떻게 될까?

RAM 은 레스토랑에서 요리하는 사람의 인원수와 같다 요리를 할 수 있는 사람의 인원수가 많다면 주문이 많이 들어와도 여러 요리를 동시에 만들 수 있기 때문에 한 요리가 완성되기를 기다리는 시간을 아낄 수 있습니다.

### RAM의 종류
---
RAM는 크게 DRAM, SRAM, SDRAM, DDR SDRAM이 있다.

DRAM : Dynamic Ram 동적메모리를 의미하며 저장된 데이터가 동적으로 사라지는 RAM을 뜻한다.
시간이 지나면 지날수록 저장된 데이터가 사라지기에 일정주기를 가지고 재활성화를 해주어야 한다.

SRAM : Static RAM 정적메모리를 의미하며, 저장된 데이터가 변하지 않는 RAM을 뜻한다.
일반적으로 DRAM보다 속도도 빠른편이다. 하지만 주로 사용되는것은 DRAM이다.
집적도가 낮고, 소비전력도 크고, 가격도 비싸기 때문이다. 때문에 필요한 곳에서만 사용된다.(캐시 메모리)

SDRAM : Synchronous Dynamic RAM 클럭신호와 동기화된, 발전된 DRAM을 뜻한다.
즉, 클럭 타이밍에 맞춰서 CPU와 데이터를 주고받을 수 있게 된 메모리를 뜻한다.

DDR SDRAM : Double Data Rate RAM 대역폭을 넓혀서 속도를 빠륵게한 SDRAM을 뜻한다.
한 클럭에 하나씩 데이터를 주고받는 SDRAM과 다르게 한 클럭에 2배의 데이터를 주고받는게 특징이다.

DDR2, DDR3, DDR4등 메모리를 칭할때 사용되는 단어는 기본 SDRAM의 2^n 만큼의 대역폭을 가지고 있다는 뜻이다.

### 메모리 주소
---
메모리에 저장된 정보의 위치는 주소값으로 나타낼 수 있다고들 하지만 이 주소에는 2종류가 있다.
메모리 하드웨어가 사용하는 *물리주소* 와 CPU와 실행중인 프로그램이 사용하는 *논리주소* 두 가지이다.

*물리주소* 는 정보가 실제로 저장된 하드웨어상의 주소를 의미하고,
*논리주소* 는 실행중인 프로그램 각각에게 부여된 0번지부터 시작되는 주소를 의미한다.

CPU는 논리주소를 사용한다고 해도 메모리와 상호작용하려면 논리주소와 물리주소간의 변환이 가능해야한다.
이를 위한 장치가 CPU 와 주소버스 사이에 있는 *메모리 관리 장치 (Memory Management Unit) MMU다.*

MMU는 CPU가 발생시킨 논리 주소에 베이스 레지스터 값을 더해서 논리 주소를 물리 주소로 변환한다.

여기서 베이스 레지스터는 *프로그램의 가장 작은 물리 주소, 프로그램의 첫 물리주소를 저장*
논리주소는 *프로그램의 시작점으로부터 떨어진 거리* 이다.

![MMU](/assets/img/MMU.png)

또한 다른 프로그램의 영역을 침범할 수 있는 명령어는 위험하기 때문에 논리 주소 범위를 벗어나는 명령어 실행을 방지하고 실행 중인 프로그램이 다른 프로그램에 영향을 받지 않도록 보호할 방법이 필요한데, 이걸 *한계 레지스터* 가 담당하게 된다.

한계 레지스터는 *논리 주소의 최대 크기를 저장한다.* 이를 통해서 프로그램의 물리 주소 범위는 베이스 레지스터 값 이상, 베이스 레지스터 값 + 한계 레지스터 값 미만이 된다.

CPU는 메모리에 접근하기 전에 접근하고자 하는 논리 주소가 한계 레지스터 보다 작은지 항상 체크하고 범위를 벗어나면 인터럽트를 발생시켜서 실행 중인 프로그램의 독립적인 실행 공간을 확보하고 하나의 프로그램이 다른 프로그램을 침범하지 못하게 보호할 수 있다.

![MMU Interupt](/assets/img/MMU%20Interupt.png)

## 캐시 메모리
---
CPU 는 프로그램을 실행하는 과정에서 메모리에 저장된 데이터를 빈번하게 사용한다. 하지만 CPU 가 메모리에 접근하는 시간은 자신의 연산 속도보다 느리다. 연산보다 메모리 접근시간이 느리면 CPU 가 얼마나 빨라도 의미가 없어진다. 이를 해결하기 위해서 만들어진게 캐시 메모리다.

캐시 메모리(Cache Memory)는 CPU 와 메모리 사이에 위치하고, 레지스터 보다 용량이 크고 메모리보다 빠른 SRAM기반의 저장장치로 CPU 의 연산 속도와 메모리 접근 속도간의 차이를 메우기 위해서 생긴 것이다.

우리가 사용하는 PC내부에는 여러개의 캐시 메모리가 존재하는데 CPU 에 가까운 순으로 계층을 구성한다. 제일 가까운 캐시 메모리를 L1 캐시, 점점 멀어질수록 L2 캐시, L3 캐시 라고 부른다. 

메모리 용량 : L1 < L2 < L3  | 속도 : L3 < L2 < L1
### 참조 지역성 원리
---
용량이 작은 캐시 메모리에 일반 메모리에 있는 모든 내용을 저장할 수는 없다. 메모리가 보조기억장치의 일부를 복사해 저장하는 것처럼 캐시 메모리도 동일하게 작동된다. 저장되는것은 *CPU 가 사용할 만한 대상을 예측해서 저장한다.*  예측한 데이터가 실제로 맞아 CPU 내부에서 사용하게 되면 *캐시 히트 (Cache Hit)* 라고하고 예측이 틀려서 직접 메모리에서 데이터를 가져와야하는 경우를 *캐시 미스 (Cache Miss)* 라고 한다.

예측이 잘 맞는지 확인하는 지표로 캐시 적중률을 사용하게 되는데 계산식이 다음과 같다.

> 캐시 적중률 : 캐시 히트 횟수 / (캐시 히트 횟수 + 캐시 미스 횟수)

일반적인 PC 의 캐시 적중률은 85~95% 이상을 보인다.

위에서 캐시메모리는  *CPU 가 사용할 만한 대상을 예측해서 저장한다* 라고 했는데 이걸 어떻게 예측 하냐면
*참조 지역성의 원리* 를 한가지의 원칙으로 가져올 데이터를 정한다. CPU 는 최근에 접근했던 메모리에 다시 접근하려는 경향 *(시간 지역성)* 이 있고 접근한 메모리 근처를 접근하려고 하기 때문에 *(공간 지역성)* 이 두가지의 원칙을 가지고 CPU 가 사용할 만한 데이터를 예측한다.

### 저장 장치 계층 구조
---
우리는 컴퓨터가 사용하는 저장 장치들은 *CPU 에 얼마나 가까운가* 를 기준으로 계층적으로 표현한다.

  ![저장 장치 계층 구조](/assets/img/Storage%20Hierarchy.png)


### Reference
---
[혼자 공부하는 컴퓨터구조 + 운영체제](https://product.kyobobook.co.kr/detail/S000061584886?utm_source=google&utm_medium=cpc&utm_campaign=googleSearch&gt_network=g&gt_keyword=&gt_target_id=aud-901091942354:dsa-1974044871038&gt_campaign_id=9979905549&gt_adgroup_id=132556570510&gad_source=1&gclid=CjwKCAjw8diwBhAbEiwA7i_sJbemSZyZm0pluIpaRXmbDOv8OEM3pQz0DIO1xd-cECAIwupwQLnvOBoCb1wQAvD_BwE)
